services:
  ollama-server:
    image: ollama/ollama
    container_name: ollama-server
    ports:
      - "${LLM_ENDPOINT_PORT}:11434"
    environment:
      - no_proxy=${NO_PROXY}
      - http_proxy=${http_proxy}
      - https_proxy=${https_proxy}
      - LLM_MODEL_ID=${LLM_MODEL_ID}
      - host_ip=${HOST_IP}

networks:
  default:
    driver: bridge